---
jupytext:
  formats: ipynb,md:myst
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.13.6
kernelspec:
  display_name: Python 3 (ipykernel)
  language: python
  name: python3
---

Merci de **ne pas modifier** le nom de ce notebook (même pour y inclure son nom).

Quelques conseils:
- pour exécutez une cellule, cliquez sur le bouton *Exécuter* ci-dessus ou tapez **Shift+Enter**
- si l'exécution d'une cellule prend trop de temps, sélectionner dans le menu ci-dessus *Noyau/Interrompre*
- en cas de très gros plantage *Noyau/Redémarrer*
- **sauvegardez régulièrement vos réponses** en cliquant sur l'icone disquette ci-dessus à gauche, ou *Fichier/Créer une nouvelle sauvegarde*

----------------------------------------------------------------------------

+++ {"deletable": false, "editable": false, "nbgrader": {"cell_type": "markdown", "checksum": "77eb7162e240c86e1626f828154e18d5", "grade": false, "grade_id": "cell-f302e66fcc925b57", "locked": true, "schema_version": 3, "solution": false, "task": false}}

# TP 10 : statistiques et le module Pandas


## Exercice 1 : retour sur la marche aléatoire à 1D

Dans cet exercice il s'agit de simuler une marche aléatoire dans un espace unidimensionnel. Vous pourrez reprendre des parties de code écrites lors des TD précédents. Au début la particule se trouve dans la position $x=0$ et à chaque étape la particule se déplace aléatoirement d'une quantité $dx$ comprise dans l'intervalle [-1,1[.
1. Représentez sur un histogramme (voir `pyplot.hist`) la position finale de 300 particules après 600 pas. Calculez la valeur moyenne des positions finales ainsi que l'écart type.
2. Définissez une fonction gaussienne 
	$$ f(x)= \frac{A}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\bar{x})^2}{2\sigma^2}}$$
Calculez cette fonction dans le domaine des $x$ défini par les extrêmes de votre distribution des positions finales des particules. Vous prendrez pour $\bar{x}$ et $\sigma$ la moyenne et l'écart type calculés précédemment. Pour $A$ vous choisirez la valeur:
$$A=\frac{X}{N_{bins}}\times N_{particules}$$
où $X$ est la largeur du domaine des $x$ calculés, $N_{bins}$ est le nombre d'intervalles utilisés pour construire l'histogramme et $N_{particules}$ est le nombre de particules. 
3. Représentez $f(x)$ sur votre graphique précédent. Que pouvez-vous en déduire sur la distribution des positions finales?

```{code-cell} ipython3
---
deletable: false
nbgrader:
  cell_type: code
  checksum: 369a5320ce8796409fb209ce4df981b1
  grade: true
  grade_id: cell-ab2b980123cd7fe0
  locked: false
  points: 0
  schema_version: 3
  solution: true
---
import numpy as np




```

+++ {"deletable": false, "editable": false, "nbgrader": {"cell_type": "markdown", "checksum": "a7c1b0f4733d89f2faf0acf2f8286f0f", "grade": false, "grade_id": "cell-2485a5d63c6c37bf", "locked": true, "schema_version": 3, "solution": false, "task": false}}

## Exercice 2 : creation et manipulation de DataFrames 

On considère deux séries de données :

    I(A)=[0.1, 0.2, 0.3, 0.4, 0.5, 0.7, 0.8, 0.9, 1]
    U(V)=[0.3, 0.7, 0.9, 1.1, 1.6, 2.3, 2.2, 2.8, 3.1]

1. Créer un Dataframe possédant 2 colonnes (intensite et tension) avec les valeurs ci-dessus
2. Avec les méthodes `head()` et  `tail()` afficher les 3 premières  et dernières ligne de ce DataFrame
3. Avec la méthode `.iloc()` afficher la 6ème ligne.  
4. En utilisant l'index afficher les lignes 3 à 5 inclus. 
5. Afficher la ligne où l'intensité est supérieur ou égale à 0.3 A et inférieur à 0.8 A.
6. En utilisant les colonnes de notre DataFrame créer une colonne comptenant la valeur de la resitance  et les colonnes contenu dans notre Dataframe
7. Avec les methodes appartenant à la classe Dataframes calculer la valeur moyenne, mediane et l'écart type des resistances. Afficher les lignes du DataFrame pour lesquelles les valeurs de la resistance sont inférieur ou égale à la médiane.
8. Qu'observez-vous si vous utilisez la méthode .values sur une des colonne du DataFrame ? et sur tout le DataFrame ? 
9. Exporter en CSV le DataFrame sous le nom `data/donnees_tp.csv` puis ouvrir ce fichier avec LibreOffice Calc.

```{code-cell} ipython3
---
deletable: false
nbgrader:
  cell_type: code
  checksum: 808f38942f0f4bf0cf836fd2a55f1634
  grade: true
  grade_id: cell-d0a0708ea306e47c
  locked: false
  points: 0
  schema_version: 3
  solution: true
  task: false
---
import pandas as pd

I = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]
U = [0.3,0.7,0.9,1.1,1.6,2.3,2.2,2.8,3.1]
    
data = pd.DataFrame({'I(A)': pd.Series(I),
        'U(V)': pd.Series(U)})

print(data.head(3))
print(data.tail(3))  

print(data.iloc[6])

print(data[3:6])

print(data[(data['I(A)']>=0.3) & (data['I(A)']<0.8)])


R = []
for i in range(len(data['I(A)'])):
    R.append(U[i]/I[i])
    
data['R(Ω)'] = R
print(data)

data_ecart = np.std(data['R(Ω)'])
data_median = np.median(data['R(Ω)'])
data_mean = np.mean(data['R(Ω)'])

print(data[data['R(Ω)']<= data_median])
```

## Exercice 3 :  avis aux amateurs d'écureuils


Des amateurs d'écureuils ont compté et observé les écureuils pour construire un dataset disponible à l'adresse suivante : `https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-29/nyc_squirrels.csv`

1. Télécharger le dataset avec la méthode [read_csv](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) et le lien ci-dessus.
2. Combien d'écureuils ont été répertorié ?
3. Quels éléments d'information ont été répertorié sur ces écureuils ?
4. Faire un graphique avec la fonction `plt.scatter` représentant la position de tous ces écureuils (longitude en fonction de la latitude)
5. En déterminant la latitude et longitude moyenne, et à l'aide de google map, trouver où ses petites bêtes ont été observées.
6. Quelle est l'activité (colonne `other_activities`) de l'écureuil 114 ?
7. Toujours dans la colonne `other_activities`, trouver l'écureuil rebelle qui se bat avec sa mère (`wrestling with mother`) et le positionner sur le graphique de la question 4.
8. Grouper les écureuils par couleurs principales de leur fourrure. Quelle est la couleur principale la plus rare dans la population d'écureuil ?
9. Représenter cette population sur le graphique.

```{code-cell} ipython3
---
deletable: false
nbgrader:
  cell_type: code
  checksum: b1a606e7a1aff6b743d0e5ad72b1e9df
  grade: false
  grade_id: cell-af11d53e2d086439
  locked: false
  schema_version: 3
  solution: true
  task: false
---
import matplotlib.pyplot as plt

squirrels = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-29/nyc_squirrels.csv')

print(len(squirrels))
print(squirrels.columns)

xa = squirrels.plot(kind='scatter', x='lat', y='long',s=1)
print(squirrels["lat"].mean(), squirrels["long"].mean())

print(squirrels.iloc[114]['other_activities'])

rebel = squirrels[squirrels['other_activities'] == 'wrestling with mother']
rebel.plot(ax=xa,kind='scatter',x='lat', y='long', color = 'r')

plt.figure()
color = squirrels.groupby('primary_fur_color')
c = color['primary_fur_color'].count()
c.plot(kind='pie')
print(c)
```

+++ {"deletable": false, "editable": false, "nbgrader": {"cell_type": "markdown", "checksum": "ddab1cd3cf00c1cc647d6079d5f745c7", "grade": false, "grade_id": "cell-9ae9dd7be6c3660d", "locked": true, "schema_version": 3, "solution": false, "task": false}}

## Exercice 4: les communes de France

 
Dans cet exercice il s'agit d'analyser une base de données qui comprend une trentaine d'indicateurs décrivant la population, les logements, les revenus, l'emploi et les établissements des communes de France. 
Ces données se trouvent dans le fichier `data/communes.csv`.
Ces données sont librement accessibles également sur le site de l'INSEE (https://www.insee.fr/fr/statistiques/2521169). La librairie pandas est un outils trés puissant: les questions suivantes peuvent être résolues en seulement une ou deux lignes! 
 
1. Importer le fichier communes.csv.
2. Analyser le titre des colonnes. Re-importer le fichier en utilisant le nom de la commune comme indice de référence pour les lignes.
3. Combien de communes y a-t-il en France?
4. Quelle est la population de la ville de Nantes?
5. Dans quelle région se trouve "Le Diamant" ? (Voir fichier csv : `data/region2019.csv`) 
6. Comment a évolué la population Française entre 2009 et 2014?
7. Donner la moyenne, l'écart-type  et la médiane de la population des communes de France. Pourquoi la moyenne ne donne pas toujours une bonne représentation des données ?
8. Combien de communes ont-elles moins de 100 habitants?
9. Quelles sont les communes les moins peuplées de France?
10. Quelle est la commune la plus peuplée? 
11. Dériver le bilan migratoire de chaque commune en regard de la population en 2014 et en 2009 ainsi que les taux de décès et de naissances pendant cette période. Combien de personnes ont-elles quitté Paris pendant cette période?
12. Définir un nouveau DataFrame dans lequel on enregistrera les densités de population des communes et leur département. Nommer les deux colonnes "Densité'' et "Département''.
13. Quelle est la commune avec la plus haute densité d'habitants en France?
14. Grouper les données des communes par département avec en paramètres `sort=False` dans la méthode `groupby`. Quel est le département le plus peuplé? 
15. Ordonner par ordre croissant les valeurs de la population par département (voir la méthode [`sort_values()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html)) et représenter cette information par un diagramme à barres.
16. Grouper les données par région. Représenter sur un diagramme circulaire la population en 2014 des différentes régions. Utiliser le fichier region2019.csv pour légender le diagramme.

```{code-cell} ipython3
---
deletable: false
nbgrader:
  cell_type: code
  checksum: 45d2d24221a7eed3a477a8d323e500a2
  grade: true
  grade_id: cell-be6bf50e0c8f954b
  locked: false
  points: 0
  schema_version: 3
  solution: true
---
communes = pd.read_csv("data/communes.csv", index_col='Nom')
print(communes.columns)

print(communes.shape)

print(communes.loc['Nantes']['Population en 2014'])
```

+++ {"deletable": false, "editable": false, "nbgrader": {"cell_type": "markdown", "checksum": "49f149c5b3bca1d998d1ed094cb4cb54", "grade": false, "grade_id": "cell-741a8d6d2329e0d3", "locked": true, "schema_version": 3, "solution": false, "task": false}}

## Exercice 5 : les prénoms

 
Dans cet exercice il s'agit d'analyser une base de données qui porte sur les prénoms donnés à Paris entre 2004 et 2018. 
Ces données se trouvent dans le fichier liste_des_prenoms.csv.
Ces données sont librement accessibles également sur le site opendata de la ville de Paris (https://opendata.paris.fr/explore/dataset/liste_des_prenoms).  
 
1. Importer le fichier liste_des_prenoms.csv.
2. Analyser les données contenues dans le fichier. Afficher les 10 premières lignes du fichier (voir `df.head()`).
3. Combien de prénoms féminins et masculins y-a-t-il dans ce fichier? Quel est le prénom masculin le plus déclaré ? en quelle année ?
Quel est le prénom féminin le plus déclaré ? en quelle année ?
4. Combien y-a-t-il de prénoms composés ? (On pourra éventuellement utiliser `Series.str.contains()` du module Pandas.)
5. Afficher les données correspondant à votre prénom .
6. Afficher Les prénoms épicènes ou mixtes, combien y-en a-t-il? (On pourra éventuellement utiliser `df.merge()` et `Series.duplicated()` du module Pandas.)

```{code-cell} ipython3
---
deletable: false
nbgrader:
  cell_type: code
  checksum: 490dc8ff5d650e5545e61c2b710f80b2
  grade: true
  grade_id: cell-e92be3cbc9f7ac4d
  locked: false
  points: 0
  schema_version: 3
  solution: true
  task: false
---
#LA REPONSE ICI
```

+++ {"deletable": false, "editable": false, "nbgrader": {"cell_type": "markdown", "checksum": "6fb1583a145dd85054dde6679ac5df44", "grade": false, "grade_id": "cell-0e30991e757ddbb2", "locked": true, "schema_version": 3, "solution": false, "task": false}}

## Exercice 6 : orbites de la sonde B de la mission THEMIS (facultatif)

La mission THEMIS à été lancée en 2007, elle est composée de 5 satellites. Nous allons nous intéresser plus particulièrement aux orbites de la sonde B de 2009 à 2011. L'unité utilisée sera le rayon terrestre ( $1 Re = 6378.1 km$ )

1. Ouvrir le fichier `data/position_gse_THB_2009_2011.pkl` avec la méthode [read_pickle()](https://pandas.pydata.org/docs/reference/api/pandas.read_pickle.html) de Pandas. Que représente l'index et comment est-il échantillonné ? Les unités des quantités angulaires sont des *radians*.
2. Appliquer la méthode `.resample('10T').asfreq()` au dataframe. Qu'observez-vous ?
3. Les données sont en coordonnées sphériques, créez une fonction qui permet de passer en coordonnées cartésiennes  en retournant trois tableaux `x,y,z` selon les formulées de transformation de coordonnées :

$$ x = R \cos(\theta) $$
$$ y = R \sin(\theta) \sin(\phi) $$
$$ z = R \sin(\theta) \cos(\phi) $$


4. Calculer les coordonnées cartésiennes $x,y,z$. Les tableaux retourner sont en fait des Series (le vérifier). Ajouter les noms des composantes aux Series obtenues. Ajouter ces dernières au DataFrame contenant les positions en coordonnées sphériques en utilisant la fonction pd.concat().
5. La mission THEMIS ayant des orbites très équatoriales, on se propose de tracer seulement les positions suivant les axes $x$ et $y$. Tracer sur la même figure les orbites correspondant aux 2 périodes suivantes :
        - Du 2 août 2009 au 12 août 2009 : indices `2009-08-02 00:00:00` à `2009-08-12 00:00:00`
        - Du 1er août 2011 au 1er septembre 2011 : indices `2011-08-01 00:00:00` à `2011-09-01 00:00:00`

    Mettre un point en (0,0) représentant la Terre. 


6. On peut voir que les orbites de ces deux périodes sont très différentes. Comment expliquer ces différences ? Indice : on peut voir que le satellite à une trajectoire hélicoïdale autour de la Terre lors de la deuxième période et fait le tour de la Terre en un peu moins de 1 mois.

7. Ouvrir le fichier `data/body_orbit_2011.pkl` qui contient les positions d'un corps céleste sur la 2ème période et tracer son orbite sur la figure précédente. Attention, l'unité de distance dans ce fichier est le km. Est ce que la trajectoire de ce corps est compatible avec votre hypothèse précédente ?

8. **Bonus :** tracer sur une nouvelle figure toutes les positions en $x$ et $y$ de la sonde B pour observer le changement d'orbite.

```{code-cell} ipython3
---
code_folding: []
deletable: false
nbgrader:
  cell_type: code
  checksum: 1b9aa6ef5c1da38a165f3c2dfcf95fa4
  grade: true
  grade_id: cell-13ec481a28b3c23f
  locked: false
  points: 0
  schema_version: 3
  solution: true
  task: false
---
#LA REPONSE ICI
```

```{code-cell} ipython3

```
