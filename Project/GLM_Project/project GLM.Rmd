---
title: "Projet GLM 2026"
author: "Thaïs Forest"
date: "2026-01-12"
output: html_document
---

# Setup.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Setting randomnes for some reproducibility.

```{r}
set.seed(42)
```

## Importation of useful packages. 

```{r}
install.packages("dbplyr") 
install.packages("textshaping")
install.packages("ggfortify")
install.packages("parallelly")
install.packages("car")
install.packages("rsample")
install.packages('GGally')
install.packages("corrplot")
install.packages('Metrics')
```

# Data importation and verifications.

```{r}
library(rmarkdown)
library(dplyr)
exam_full <- read.csv("project.csv")
dim(exam_full)
str(exam_full)
summary(exam_full)
names(exam_full)
```

## Erase the variable ID.

```{r}
exam <- exam_full %>% dplyr::select(-id)
```

## Factorise the variable and labelized for a better comphrehension.

```{r}
exam <- exam %>%
  mutate(
    sexe = factor(sexe, levels = c(1,2,3), labels = c("Female","Male","Other")),
    school_type = factor(school_type, levels = c(1,2), labels = c("Public","Private")),
    parent_educ = factor(parent_educ, levels = 1:6,
                         labels = c("No formal","High school","Graduate",
                                    "Post graduate 1","Post graduate 2","PhD")),
    sleep_qual = factor(sleep_qual, levels = c(1,2,3), labels = c("Poor","Average","Good"),
                        ordered = TRUE),
    web_access = factor(web_access, levels = c(1,2), labels = c("No","Yes")),
    trav_time = factor(trav_time, levels = c(1,2,3,4),
                       labels = c("<15 min","15–30 min","30–60 min",">60 min"),
                       ordered = TRUE),
    extra_act = factor(extra_act, levels = c(1,2), labels = c("No","Yes")),
    study_method = factor(study_method, levels = 1:6,
                          labels = c("Online videos","Coaching","Notes",
                                     "Textbook","Group study","Mixed")),
    agecat = factor(agecat, levels = c(1,2,3,4,5), labels = c("14-15","15-16","16-17","17-18","18-19")),
    attend_pct_cat = factor(attend_pct_cat, levels = c(1,2,3,4), labels = c("50-62","62-72","72-81","81-100"))
    
  )


paged_table(exam)
```

## Visual analysis checking for aberant value.

```{r}
summary(exam$y)
summary(exam$age)
summary(exam$study_hrs)
summary(exam$sleep_hrs)
summary(exam$attend_pct)
```

```{r}
stopifnot(all(exam$attend_pct >= 0 & exam$attend_pct <= 100, na.rm = TRUE))
stopifnot(all(exam$study_hrs >= 0, na.rm = TRUE))
stopifnot(all(exam$sleep_hrs >= 0, na.rm = TRUE))
```

```{r}
colSums(is.na(exam))
```

# Exploratory data analysis.

## Y.

```{r}
summary(exam$y)
hist(exam$y, breaks = 35, col='tan1',
     main = "Distribution of exam scores",
     xlab = "exam score")
abline(v = mean(exam$y), col='red4', lwd = 3)


boxplot(exam$y,
        main = "exam scores",
        ylab = "scores")
```

## Quantitative variables.

```{r}
num_vars <- exam %>%
  dplyr::select(where(is.numeric))

num_vars <- num_vars %>% dplyr::select(-y)
summary(num_vars)

library(ggplot2)

plots_num <- list()

for (var in names(num_vars)) {
  
  p <- ggplot(exam,
              aes(x = .data[[var]], y = y)) +
    geom_point(alpha = 0.4, col = 'skyblue') +
    geom_smooth(method = "loess", se = FALSE, col = 'tan1') +
    geom_smooth(method = "lm", linetype = "dashed") +
    labs(
      x = var,
      y = "Exam score",
      title = paste("Exam score vs", var)
    )
  
  plots_num[[var]] <- p
}

print(plots_num)
```

## Quatitative factors.

```{r}
cat_vars <- exam %>%
  dplyr::select(where(is.factor))

cat_tables <- list()

for (var in names(cat_vars)) {
  
  tab <- table(cat_vars[[var]])
  prop <- round(100 * prop.table(tab), 1)
  
  cat_tables[[var]] <- data.frame(
    Category = names(tab),
    Count = as.vector(tab),
    Proportion = as.vector(prop)
  )
}

print(cat_tables)
```

```{r}
library(dplyr)
library(ggplot2)

plots <- list()

for (var in names(cat_vars)) {
  
  p <- ggplot(exam,
              aes(x = .data[[var]],
                  y = y,
                  colour = .data[[var]],
                  fill = .data[[var]])) +
    geom_boxplot(alpha = 0.5, outlier.alpha = 0) +
    geom_jitter(width = 0.3, size = 0.3, alpha = 0.3) +
    stat_summary(fun = mean,
                 colour = "black",
                 geom = "point",
                 shape = 18,
                 size = 3) +
    labs(
      x = var,
      y = "Exam score",
      title = paste("Exam score by", var)
    ) +
    theme_minimal() +
    theme(legend.position = "none")
  
  plots[[var]] <- p
}

print(plots)
```

## Correlations. 

### between variables.

```{r}
library(dplyr)

library(corrplot)

correlation_matrix<-cor(num_vars)
corrplot(correlation_matrix, order = 'hclust',addrect = 3)
```

```{r}
library(GGally)

ggpairs(num_vars)
```

### with respect to objective y.  

```{r}
exam %>%
  group_by(trav_time) %>%
  summarise(mean_y = mean(y)) %>%
  ggplot(aes(x = trav_time, y = mean_y, group = 1)) +
  geom_point(size = 3) +
  geom_line()

exam %>%
  group_by(sleep_qual) %>%
  summarise(mean_y = mean(y)) %>%
  ggplot(aes(x = sleep_qual, y = mean_y, group = 1)) +
  geom_point(size = 3) +
  geom_line()

exam %>%
  group_by(parent_educ) %>%
  summarise(mean_y = mean(y)) %>%
  ggplot(aes(x = parent_educ, y = mean_y, group = 1)) +
  geom_point(size = 3) +
  geom_line()

exam %>%
  group_by(attend_pct_cat) %>%
  summarise(mean_y = mean(y)) %>%
  ggplot(aes(x = attend_pct_cat, y = mean_y, group = 1)) +
  geom_point(size = 3) +
  geom_line() +
  theme_minimal()
```

```{r}
ggplot(exam, aes(x = sleep_hrs, y = y, color = trav_time)) +
  geom_smooth(method = "loess", se = FALSE)

ggplot(exam, aes(x = study_hrs, y = y, color = attend_pct_cat)) +
  geom_smooth(method = "loess", se = FALSE)

ggplot(exam, aes(x = study_hrs, y = y, color = sleep_qual)) +
  geom_smooth(method = "loess", se = FALSE)

ggplot(exam, aes(x = study_hrs, y = y, color = parent_educ)) +
  geom_smooth(method = "loess", se = FALSE)

ggplot(exam, aes(x = study_hrs, y = y, color = extra_act)) +
  geom_smooth(method = "loess", se = FALSE)

ggplot(exam, aes(x = sleep_hrs, y = y, color = sleep_qual)) +
  geom_smooth(method = "loess", se = FALSE)

ggplot(exam, aes(x = sleep_hrs, y = y, color = attend_pct_cat)) +
  geom_smooth(method = "loess", se = FALSE)

ggplot(exam, aes(x = study_hrs, y = y, color = trav_time)) +
  geom_smooth(method = "loess", se = FALSE)


ggplot(exam,aes(x = study_hrs,y = y,color = cut(sleep_hrs,breaks = c(4, 6, 8, 10),labels = c("Low", "Medium", "High")))) +geom_smooth(se = FALSE)
```
### choice between categorical or numerical variables for redundant variables.

```{r}
library(dplyr)

plot_data <- exam %>%
  group_by(study_method, school_type) %>%
  summarise(
    mean_y = mean(y, na.rm = TRUE),
    .groups = "drop"
  )


library(ggplot2)

ggplot(plot_data,
       aes(x = study_method,
           y = mean_y,
           group = school_type,
           color = school_type)) +
  geom_line(size = 1) +
  geom_point(size = 3) +
  theme_minimal() +
  labs(
    x = " study_method",
    y = "Mean score",
    color = "School type"
  )




plot_data1 <- exam %>%
  group_by(attend_pct_cat, sleep_qual) %>%
  summarise(
    mean_y = mean(y, na.rm = TRUE),
    .groups = "drop"
  )


library(ggplot2)

ggplot(plot_data1,
       aes(x = attend_pct_cat,
           y = mean_y,
           group = sleep_qual,
           color = sleep_qual)) +
  geom_line(size = 1) +
  geom_point(size = 3) +
  theme_minimal() +
  labs(
    x = "attendance rate cat",
    y = "Mean score",
    color = "sleep_qual"
  )


plot_data2 <- exam %>%
  group_by(sleep_qual, extra_act) %>%
  summarise(
    mean_y = mean(y, na.rm = TRUE),
    .groups = "drop"
  )


library(ggplot2)

ggplot(plot_data2,
       aes(x = sleep_qual,
           y = mean_y,
           group = extra_act,
           color = extra_act)) +
  geom_line(size = 1) +
  geom_point(size = 3) +
  theme_minimal() +
  labs(
    x = "sleep quality",
    y = "Mean score",
    color = "extra act"
  )


plot_data3 <- exam %>%
  group_by(parent_educ, school_type) %>%
  summarise(
    mean_y = mean(y, na.rm = TRUE),
    .groups = "drop"
  )


library(ggplot2)

ggplot(plot_data3,
       aes(x = parent_educ,
           y = mean_y,
           group = school_type,
           color = school_type)) +
  geom_line(size = 1) +
  geom_point(size = 3) +
  theme_minimal() +
  labs(
    x = "parent education",
    y = "Mean score",
    color = "school type"
  )
```
## Final data set. 

```{r}
exam_top <- exam %>% dplyr::select(-agecat, -attend_pct)

dim(exam_top)
```

# Building regression models.

## Train/test split at rate 80%/20%.

```{r}
set.seed(42)
exam_split <- exam_top |> mutate(tag = rbinom(n(), size = 1, prob = 0.8))

train1 <- filter(exam_split, tag == 1)
test1 <- filter(exam_split, tag == 0)
```

```{r}
train1
```

## First models and criteria comparaition.

criteria use :  nested model
                R2 and R2 adjusted
                CP of Mallow
                RMSE
                AIC/BIC
                Type I analysis
                Type II analysis

### model reduse and full. 

```{r}
mod0<- lm(y~1,data = train1)

modfull <- lm(y~ .,data = train1)
```

### Type I and II on the full model.

```{r}
anova(modfull)
```

```{r}
library(carData)
Anova(modfull)
```

### model build for step method (bothward and AIC).

```{r}
library(MASS)

modboth <- stepAIC(mod0,y~ attend_pct_cat + parent_educ+ study_hrs + sleep_qual +  trav_time + web_access + extra_act +sleep_hrs + school_type + study_method + age + sexe,data=train1,trace=T,direction=c('both'))

modboth
```

```{r}
n <- length(train1$y)

stepAIC(mod0,y~ attend_pct_cat + parent_educ+ study_hrs + sleep_qual +  trav_time + web_access + extra_act +sleep_hrs + school_type + study_method + age + sexe,data=train1,trace=F,k=log(n),direction=c('both'))
```

### model without sexe, and comparation with full and step model.

```{r}
modanova <- lm(y~ . -sexe,data = train1)

namemod = c("modboth","modanova")
p_value1 = c(anova(modboth,modanova)$`Pr(>F)`[2],anova(modboth,modfull)$`Pr(>F)`[2])
data.frame(namemod,p_value1)

AIC(modboth, modanova, modfull)
```

### test if we use sleephour^2 and study_hours^2 more than sleephour and study_hours.

```{r}
m_sleep <- mean(train1$sleep_hrs, na.rm = TRUE)

train <- train1 %>%
  mutate(
    sleep_c  = sleep_hrs - m_sleep,
    sleep_c2 = sleep_c^2
  )

test <- test1 %>%
  mutate(
    sleep_c  = sleep_hrs - m_sleep,
    sleep_c2 = sleep_c^2
  )


m_study <- mean(train1$study_hrs, na.rm = TRUE)

train <- train %>%
  mutate(
    study_c  = study_hrs - m_study,
    study_c2 = study_c^2
  )

test <- test %>%
  mutate(
    study_c  = study_hrs - m_study,
    study_c2 = study_c^2
  )
```

## New train/test without sleephour and study_hours.

```{r}
train <- train %>% dplyr::select(-sleep_hrs)
train <- train %>% dplyr::select(-study_hrs)

test <- test %>% dplyr::select(-sleep_hrs)
test <- test %>% dplyr::select(-study_hrs)
```

## New models on this new train data set.

```{r}
mod1 <- lm(y~sleep_c + sleep_c2 + attend_pct_cat + study_c + study_c2 + trav_time + sleep_qual + 
    school_type + study_method + parent_educ + extra_act + web_access, data = train)

mod1bis <- lm(y~sleep_c + attend_pct_cat + study_c + study_c2 + trav_time + sleep_qual + 
    school_type + study_method + parent_educ + extra_act + web_access, data = train)

mod_1 <-lm(y~sleep_c + sleep_c2 + attend_pct_cat + study_c + study_c2 + trav_time + sleep_qual + 
    school_type + study_method + parent_educ + extra_act + web_access, data = train)

mod_1bis <-lm(y~sleep_c + sleep_c2 + attend_pct_cat + study_c  + trav_time + sleep_qual + 
    school_type + study_method + parent_educ + extra_act + web_access, data = train)

modfull <- lm(y~.-age , data = train)
```

## Comparation of AIC.

```{r}
namemod = c("mod1/mod1bis","mod_1/mod_1bis")
p_value1 = c(anova(mod1,mod1bis)$`Pr(>F)`[2],anova(mod_1,mod_1bis)$`Pr(>F)`[2])
data.frame(namemod,p_value1)

AIC(mod1, mod1bis,mod_1, mod_1bis, modfull)
```

```{r}
Criterion = c("R ajusted for mod1","R ajusted for mod1bis","cp for mod_1", "cp for mod_1bis","R ajusted for mod1","R ajusted for mod1bis","cp for mod_1", "cp for mod_1bis" )
R = c(summary(mod1)$adj.r.squared,summary(mod1bis)$adj.r.squared,summary(mod_1)$adj.r.squared,summary(mod_1bis)$adj.r.squared)

n1 <- nrow(train)
p1 <- length(coef(mod1))
p2 <- length(coef(mod1bis))
p_1 <- length(coef(mod_1))
p_2 <- length(coef(mod_1bis))

sigma2_full <- sum(residuals(modfull)^2) / df.residual(modfull)

Cp_mod1 <- sum(residuals(mod1)^2) / sigma2_full - (n1 - 2 * p1)
Cp_mod1bis <- sum(residuals(mod1bis)^2) / sigma2_full - (n1 - 2 * p2)
Cp_mod_1 <- sum(residuals(mod_1)^2) / sigma2_full - (n1 - 2 * p_1)
Cp_mod_1bis <- sum(residuals(mod_1bis)^2) / sigma2_full - (n1 - 2 * p_2)

CP =c(Cp_mod1,Cp_mod1bis,Cp_mod_1,Cp_mod_1bis)
value = c(R,CP)

data.frame(Criterion,value)
```

## Test of interactions suggest by the EDA.

### simple interations with study_c + study_c2

```{r}
mod00 <- lm(y~(sleep_c + sleep_c2) + attend_pct_cat + (study_c +study_c2) + trav_time + sleep_qual + study_method + extra_act + parent_educ*school_type + web_access , data = train)

mod2 <- lm(y ~(study_c + study_c2)*(attend_pct_cat)+sleep_c + sleep_c2 + trav_time + parent_educ*school_type + extra_act + sleep_qual  + web_access + study_method , data = train)

mod3 <- lm(y ~(study_c + study_c2)*(sleep_qual) + attend_pct_cat + trav_time+ sleep_c + sleep_c2 + parent_educ*school_type + extra_act  + web_access + study_method , data = train)

mod4 <- lm(y ~(study_c + study_c2)*(trav_time) + sleep_c + sleep_c2 + sleep_qual + attend_pct_cat + parent_educ*school_type + extra_act + web_access + study_method , data = train)

mod5 <- lm(y ~(study_c + study_c2)*(sleep_c + sleep_c2) + trav_time + sleep_qual + attend_pct_cat + parent_educ*school_type + extra_act  + web_access + study_method , data = train)
```

```{r}
anova(mod00,mod2)$`Pr(>F)`[2]
anova(mod00,mod3)$`Pr(>F)`[2]
anova(mod00,mod4)$`Pr(>F)`[2]
anova(mod00,mod5)$`Pr(>F)`[2]
```

```{r}
mod6 <- lm(y ~(study_c +study_c2)*(sleep_c + sleep_c2 + attend_pct_cat) + sleep_qual + trav_time + parent_educ*school_type + extra_act + web_access + study_method , data = train)

mod7 <- lm(y ~(study_c + study_c2)*(sleep_qual + attend_pct_cat) + trav_time + sleep_c + sleep_c2  + parent_educ*school_type + extra_act + web_access + study_method , data = train)

mod8 <- lm(y ~(study_c + study_c2)*(sleep_qual + sleep_c + sleep_c2 + attend_pct_cat)+ trav_time + parent_educ*school_type + extra_act  + web_access + study_method , data = train)

mod9 <- lm(y ~(study_c + study_c2)*(sleep_qual + sleep_c + sleep_c2 + attend_pct_cat + trav_time) + parent_educ*school_type + extra_act  + web_access + study_method , data = train)
```

```{r}
anova(mod2,mod7)$`Pr(>F)`[2]
```

```{r}
modI <- mod5
modII <- mod7
```

We select mod7.

### interaction with sleep_qual

```{r}
mod10 <- lm(y ~ sleep_qual*(attend_pct_cat) + study_c + study_c2 + sleep_c + sleep_c2 + trav_time + parent_educ*school_type + extra_act + web_access + study_method, data = train)

mod11 <- lm(y ~ sleep_qual*(study_c + study_c2) + attend_pct_cat + sleep_c + sleep_c2 + trav_time + parent_educ*school_type + extra_act + web_access + study_method, data = train)

mod12 <- lm(y ~ sleep_qual*(extra_act) + attend_pct_cat + sleep_c + sleep_c2 + trav_time + parent_educ*school_type + study_c + study_c2 + web_access + study_method, data = train)

mod13 <- lm(y ~ sleep_qual*(sleep_c + sleep_c2) + attend_pct_cat + study_c + study_c2 + trav_time + parent_educ*school_type + extra_act + web_access + study_method, data = train)
```

```{r}
anova(mod00,mod10)$`Pr(>F)`[2]
anova(mod00,mod11)$`Pr(>F)`[2]
anova(mod00,mod12)$`Pr(>F)`[2]
anova(mod00,mod13)$`Pr(>F)`[2]
```

```{r}
mod14 <- lm(y ~ sleep_qual*(study_c + study_c2 + attend_pct_cat) + sleep_c + sleep_c2 + trav_time + parent_educ*school_type + extra_act + web_access + study_method, data = train)

mod15 <- lm(y ~ sleep_qual*(study_c + study_c2 + extra_act + attend_pct_cat) + trav_time + parent_educ*school_type + sleep_c + sleep_c2  + web_access + study_method, data = train)
```

```{r}
anova(mod14,mod15)$`Pr(>F)`[2]
```

```{r}
modIII <- mod14
```

```{r}
mod16 <- lm(y ~  (sleep_c + sleep_c2)*(attend_pct_cat)+study_c +study_c2  + trav_time+sleep_qual+extra_act+ parent_educ*school_type + web_access + study_method, data = train)

mod17 <- lm(y ~  (sleep_c + sleep_c2)*(study_c +study_c2)+attend_pct_cat   + trav_time+sleep_qual+extra_act+ parent_educ*school_type + web_access + study_method, data = train)

mod18 <- lm(y ~  (sleep_c + sleep_c2)*(sleep_qual)+attend_pct_cat   + trav_time+study_c +study_c2 +extra_act+ parent_educ*school_type + web_access + study_method, data = train)
```

```{r}
anova(mod00,mod16)$`Pr(>F)`[2]
anova(mod00,mod17)$`Pr(>F)`[2]
anova(mod00,mod18)$`Pr(>F)`[2]
```

```{r}
mod19 <- lm(y ~  (sleep_c + sleep_c2)*(attend_pct_cat+study_c +study_c2)  + trav_time+sleep_qual+extra_act+ parent_educ*school_type + web_access + study_method, data = train)
```

```{r}
anova(mod16,mod19)$`Pr(>F)`[2]
```

```{r}
modIV <- mod19
```

We select mod14 and model19.

### interaction with attend_pct_cat

```{r}
mod20 <- lm(y ~ attend_pct_cat*(study_c + study_c2) + sleep_c + sleep_c2 + sleep_qual + trav_time + parent_educ*school_type + extra_act + web_access + study_method, data = train)

mod21 <- lm(y ~ attend_pct_cat*(sleep_c + sleep_c2) + study_c + study_c2+ sleep_qual + trav_time+ parent_educ*school_type + extra_act + web_access + study_method, data = train)

mod22 <- lm(y ~ attend_pct_cat*(sleep_qual) + sleep_c + sleep_c2 + study_c + study_c2 + trav_time + parent_educ*school_type + extra_act + web_access + study_method, data = train)
```

```{r}
anova(mod00,mod20)$`Pr(>F)`[2]
anova(mod00,mod21)$`Pr(>F)`[2]
anova(mod00,mod22)$`Pr(>F)`[2]
```

```{r}
mod23 <- lm(y ~ attend_pct_cat*(sleep_c + sleep_c2 + sleep_qual) + study_c + study_c2 + trav_time + parent_educ*school_type + extra_act + web_access + study_method, data = train)

mod24 <- lm(y ~ attend_pct_cat*(sleep_c + sleep_c2) + sleep_qual*(study_c + study_c2) + trav_time + parent_educ*school_type + extra_act + web_access + study_method, data = train)

mod30 <- lm(y ~ attend_pct_cat*(sleep_c + sleep_c2) + sleep_qual*extra_act + trav_time+ parent_educ*school_type + study_c + study_c2 + web_access + study_method, data = train)

mod31 <- lm(y ~ attend_pct_cat*(sleep_c + sleep_c2) + sleep_qual*extra_act + trav_time*(study_c + study_c2) + parent_educ*school_type + web_access + study_method, data = train)

mod32 <- lm(y ~ attend_pct_cat*(sleep_c + sleep_c2) + sleep_qual + extra_act + trav_time*(study_c + study_c2) + parent_educ*school_type + web_access + study_method, data = train)
```

```{r}
anova(mod21,mod24)$`Pr(>F)`[2]
```

```{r}
modV <- mod24
```

```{r}
mod25 <- lm(y ~ trav_time*(study_c + study_c2 )+ sleep_qual+ attend_pct_cat+ sleep_c + sleep_c2 + parent_educ*school_type +extra_act+ web_access + study_method, data = train)

mod26 <- lm(y ~ trav_time*( sleep_c + sleep_c2)+ sleep_qual+ attend_pct_cat+ study_c + study_c2 + parent_educ*school_type +extra_act+ web_access + study_method, data = train)
```

```{r}
anova(mod00,mod25)$`Pr(>F)`[2]
anova(mod00,mod26)$`Pr(>F)`[2]
```

```{r}
mod27 <- lm(y ~ trav_time*(study_c + study_c2+ sleep_c + sleep_c2)+ sleep_qual+ attend_pct_cat  + parent_educ*school_type +extra_act+ web_access + study_method, data = train)
```

```{r}
anova(mod25,mod27)$`Pr(>F)`[2]
```
```{r}
mod28 <- lm(y ~ trav_time*(study_c + study_c2+ sleep_c + sleep_c2)+ sleep_qual*extra_act +attend_pct_cat  + parent_educ*school_type + web_access + study_method, data = train)

mod29 <- lm(y ~ trav_time*(study_c + study_c2+ sleep_c + sleep_c2)+ sleep_qual*attend_pct_cat +  extra_act+ parent_educ*school_type + web_access + study_method, data = train)
```

```{r}
anova(mod27,mod29)$`Pr(>F)`[2]
```

```{r}
modVI <- mod29
```

We select mod24 and mod29

## We select the best model from those selected and those build with other interaction.

```{r}
modVII <- lm(y ~ attend_pct_cat*(sleep_c + sleep_c2)*(study_c + study_c2) +sleep_qual+extra_act + trav_time+ parent_educ*school_type + web_access + study_method, data = train)

modVII <- lm(y ~ (sleep_c + sleep_c2) *(attend_pct_cat) + (sleep_c + sleep_c2)*(study_c + 
    study_c2) +(attend_pct_cat)*(study_c + 
    study_c2)+ trav_time + sleep_qual + extra_act + parent_educ * 
    school_type + web_access + study_method, data = train)

modVIII <- lm(y ~ (sleep_c + sleep_c2)*(study_c + 
    study_c2) +(attend_pct_cat)*(study_c + 
    study_c2)+ trav_time + sleep_qual + extra_act + parent_educ * 
    school_type + web_access + study_method, data = train)

modIX <- lm(y ~ (sleep_c + sleep_c2) *(attend_pct_cat) + (sleep_c + sleep_c2)*(study_c + 
    study_c2) +(attend_pct_cat)*(study_c + 
    study_c2)+ trav_time + sleep_qual + parent_educ * 
    school_type + study_method, data = train)

modX <- lm(y ~ (sleep_c + sleep_c2)*(study_c + 
    study_c2) +(attend_pct_cat)*(study_c + 
    study_c2)+ trav_time + (study_c + 
    study_c2)*sleep_qual + extra_act + parent_educ * 
    school_type + web_access + study_method, data = train)

modXI <- lm(y ~ (study_c +study_c2)*( sleep_c + sleep_c2 +sleep_qual ) +trav_time+(study_c +study_c2)*attend_pct_cat+extra_act+study_method+ parent_educ*school_type , data = train)

modXII <- lm(y ~ (study_c +study_c2)*( sleep_c + sleep_c2 +sleep_qual) +trav_time+attend_pct_cat+web_access+extra_act+study_method+ parent_educ*school_type , data = train)
```

```{r}
anova(modX,modIX)
```

```{r}
models <- list(modI =modI,modII =modII,modIII=modIII,modIV =modIV, modV=modV, modVI =modVI,modVII=modVII,modVIII=modVIII,modIX=modIX,modX=modX, modXI=modXI,modXII=modXII)
```

### we use AIC and BIC of each models.

```{r}
aic <- data.frame(
  Model = names(models),
  AIC   = sapply(models, AIC)
)


bic <- data.frame(
  Model = names(models),
  BIC   = sapply(models, BIC)
)

aic[order(aic$AIC), ]
bic[order(bic$BIC), ]
```

### we use R2 adjusted of each models.

```{r}
adj_r2 <- data.frame(
  Model = names(models),
  Adj_R2 = sapply(models, function(m) summary(m)$adj.r.squared)
)

adj_r2[order(-adj_r2$Adj_R2), ]
```

### build an model with all the interactions

```{r}
full_mod <- lm(
  y ~ (study_c + study_c2) * (sleep_c + sleep_c2) * attend_pct_cat
    + (study_c + study_c2) * sleep_qual
    + (sleep_c + sleep_c2) * sleep_qual
    + sleep_qual * attend_pct_cat
    + trav_time * (study_c + study_c2 + sleep_c + sleep_c2)
    + extra_act + web_access + study_method
    + parent_educ * school_type,
  data = train
)

sigma2 <- summary(full_mod)$sigma^2
```

### we use Cp of Mallow adjusted of each models.

```{r}
cp <- sapply(models, function(m) {
  p <- length(coef(m))
  rss <- sum(residuals(m)^2)
  rss / sigma2 - (nrow(train) - 2 * p)
})

cp_table <- data.frame(
  Model = names(models),
  Cp = cp,
  p  = sapply(models, function(m) length(coef(m)))
)

cp_table[order(cp_table$Cp), ]
```

### comparative table

```{r}
comparison3 <- data.frame(
  Model   = names(models),
  AIC     = sapply(models, AIC),
  BIC     = sapply(models, BIC),
  Adj_R2  = sapply(models, function(m) summary(m)$adj.r.squared),
  Cp      = cp,
  P  = sapply(models, function(m) length(coef(m)))
)

comparison3[order(comparison3$AIC), ]
```

We select modI, modVII and modVIII 

## We use the RMSE to select the best model between modI, modVII and modVIII 

```{r}
library(Metrics)
RMSE_modI_train  <- rmse(train$y, predict(modI,  newdata = train))
RMSE_modVII_train <- rmse(train$y, predict(modVII, newdata = train))
RMSE_modVIII_train  <- rmse(train$y, predict(modVIII,  newdata = train))


RMSE_modI_test  <- rmse(test$y, predict(modI,  newdata = test))
RMSE_modVII_test <- rmse(test$y, predict(modVII, newdata = test))
RMSE_modVIII_test <- rmse(test$y, predict(modVIII, newdata = test))


RMSE_train <- c(RMSE_modI_train, RMSE_modVII_train,RMSE_modVIII_train )
RMSE_test  <- c(RMSE_modI_test,  RMSE_modVII_test, RMSE_modVIII_test)


RMSE <- rbind.data.frame(RMSE_train, RMSE_test)
names(RMSE) <- c("modI", "modVII","modVIII")
row.names(RMSE) <- c("Train", "Test")

RMSE
```

We select modVIII.


### Diagnostics, assumptions, and robustness

```{r}
summary(modVIII)
```
### linear assomptions (P1 - P4)

```{r}
library(ggfortify)
autoplot(modVIII,1,colour = 'skyblue')
autoplot(modVIII,2,colour = 'tan1')
autoplot(modVIII,3,colour = 'skyblue')
autoplot(modVIII,4,colour = 'tan1')
```

```{r}
library(car)
ncvTest(modVIII)
```

```{r}
durbinWatsonTest(modVIII)
```

```{r}
library(car)
influenceIndexPlot(modVIII,vars="Studentized")
```

```{r}
influenceIndexPlot(modVIII,vars="hat")
```
### outlier detection.

```{r}
influenceIndexPlot(modVIII,vars="cook")
```

```{r}
library(car)
outlierTest(modVIII)
```

```{r}
cook <- cooks.distance(modVIII)

# Top 5 observations les plus influentes
head(sort(cook, decreasing = TRUE), 3)
```

```{r}
idx <- order(cook, decreasing = TRUE)[1:3]

modVIII_reduced <- lm(formula(modVIII),
                   data = train[-idx, ])

summary(modVIII)
summary(modVIII_reduced)
```
## Predictive performance.

### Comparation between (trained/tested) observed and predicted values of our model. 

```{r}
pred_train <- predict(modVIII, newdata = train)
pred_test  <- predict(modVIII, newdata = test)

base_hat_train <- rep(mean(train$y), nrow(train))
base_hat_test  <- rep(mean(train$y), nrow(test))

df_train <- data.frame(y = train$y, yhat = pred_train, split = "Train")
df_test  <- data.frame(y = test$y,  yhat = pred_test,  split = "Test")
df_all   <- rbind(df_train, df_test)
```

```{r}
library(ggplot2)

ggplot(df_all, aes(x = yhat, y = y)) +
  geom_point(alpha = 0.25) +
  geom_smooth(method = "loess", se = FALSE) +
  geom_abline(slope = 1, intercept = 0, linetype = 2) +
  facet_wrap(~split) +
  labs(
    title = "Calibration: Observed vs Predicted (modVIII)",
    x = "Predicted score",
    y = "Observed score"
  )
```
## Mean observed score on test data set.

```{r}
library(dplyr)

df_test_bins <- df_test %>%
  mutate(bin = ntile(yhat, 10)) %>%
  group_by(bin) %>%
  summarise(
    yhat_mean = mean(yhat),
    y_mean    = mean(y),
    n = n(),
    .groups = "drop"
  )

ggplot(df_test_bins, aes(x = yhat_mean, y = y_mean)) +
  geom_point() +
  geom_line() +
  geom_abline(slope = 1, intercept = 0, linetype = 2) +
  labs(
    title = "Binned calibration (Test set): deciles of predicted score",
    x = "Mean predicted score (per decile)",
    y = "Mean observed score (per decile)"
  )
```
## Comparison of rmse, mse, median, R2 between our model and the median of the test set. 

```{r}
set.seed(123)
```


```{r}
rmse <- function(y, yhat) sqrt(mean((y - yhat)^2))
mse  <- function(y, yhat) mean((y - yhat)^2)
medae <- function(y, yhat) median(abs(y - yhat))
r2_oos <- function(y, yhat) 1 - sum((y - yhat)^2) / sum((y - mean(y))^2)

metrics <- data.frame(
  Model = c("Baseline", "modVIII"),
  RMSE  = c(rmse(test$y, base_hat_test), rmse(test$y, pred_test)),
  MedAE = c(medae(test$y, base_hat_test), medae(test$y, pred_test)),
  R2    = c(r2_oos(test$y, base_hat_test), r2_oos(test$y, pred_test)),
  MSE   = c(mse(test$y, base_hat_test), mse(test$y, pred_test))
)

metrics_long <- tidyr::pivot_longer(metrics, cols = c(RMSE, MedAE, R2, MSE),
                                   names_to = "Metric", values_to = "Value")

ggplot(metrics_long, aes(x = Metric, y = Value, fill = Model)) +
  geom_col(position = "dodge") +
  labs(title = "Predictive performance on Test: Baseline vs modVIII")
```
## Confidence interval at level 95% of our predictor.

```{r}
s <- summary(modVIII)
coef_tab <- as.data.frame(s$coefficients)
names(coef_tab) <- c("Estimate", "Std_Error", "t_value", "p_value")

ci <- confint(modVIII, level = 0.95)   

coef_tab$CI_low  <- ci[, 1]
coef_tab$CI_high <- ci[, 2]

coef_tab_final <- coef_tab[, c("Estimate", "Std_Error", "CI_low", "CI_high")]

coef_tab_final
```

## Comparison of predictive quality with different size of test data set.

```{r}
library(dplyr)

mse <- function(y, yhat) mean((y - yhat)^2)
rmse <- function(y, yhat) sqrt(mean((y - yhat)^2))
medae <- function(y, yhat) median(abs(y - yhat))
r2_oos <- function(y, yhat) 1 - sum((y - yhat)^2) / sum((y - mean(y))^2)

fractions <- c(0.2, 0.4, 0.6, 0.8, 1.0)
B <- 30  

res <- bind_rows(lapply(fractions, function(frac){
  bind_rows(lapply(1:B, function(b){
    idx <- sample(seq_len(nrow(train)), size = floor(frac*nrow(train)), replace = FALSE)
    tr_small <- train[idx, ]

    m_small <- lm(formula(modVIII), data = tr_small)
    pred <- predict(m_small, newdata = test)

    data.frame(
      frac = frac,
      rep = b,
      MSE = mse(test$y, pred),
      RMSE = rmse(test$y, pred),
      MedAE = medae(test$y, pred),
      R2_oos = r2_oos(test$y, pred)
    )
  }))
}))

summary_res <- res %>%
  group_by(frac) %>%
  summarise(
    mean_MSE = mean(MSE), sd_MSE = sd(MSE),
    mean_RMSE = mean(RMSE), sd_RMSE = sd(RMSE),
    mean_MedAE = mean(MedAE), sd_MedAE = sd(MedAE),
    mean_R2 = mean(R2_oos), sd_R2 = sd(R2_oos),
    .groups = "drop"
  )

summary_res
```

```{r}
library(ggplot2)

ggplot(res, aes(x = frac, y = RMSE)) +
  geom_point(alpha = 0.25) +
  geom_smooth(se = FALSE, method = "loess") +
  labs(
    title = "Stability check: Test RMSE vs training sample fraction (modVIII refit)",
    x = "Fraction of training data used",
    y = "Test RMSE"
  )
```
## Comparison of predictive quality with different size of train data set.

```{r}
ybar_full <- mean(train$y)
baseline_hat <- rep(ybar_full, nrow(test))
baseline_rmse <- rmse(test$y, baseline_hat)

res2 <- res %>%
  group_by(frac) %>%
  summarise(
    mean_RMSE = mean(RMSE),
    improve_vs_baseline = baseline_rmse - mean_RMSE,
    pct_improve = 100 * (baseline_rmse - mean_RMSE) / baseline_rmse,
    .groups="drop"
  )

res2
```

```{r}
n_small <- 1500
idx <- sample(seq_len(nrow(train)), n_small)
train_small <- train[idx, ]

K <- 5
fold_id <- sample(rep(1:K, length.out = nrow(train_small)))

cv_res <- lapply(1:K, function(k){
  tr <- train_small[fold_id != k, ]
  va <- train_small[fold_id == k, ]

  m <- lm(formula(modVIII), data = tr)
  pred <- predict(m, newdata = va)

  data.frame(
    fold = k,
    RMSE = rmse(va$y, pred),
    MSE  = mse(va$y, pred),
    MedAE = medae(va$y, pred),
    R2_oos = r2_oos(va$y, pred)
  )
}) %>% bind_rows()

cv_res
summary(cv_res)
```
## Prediction of new observations (confidence interval of it grade).

```{r}
A_study_c <- -1.0
B_study_c <-  1.5
A_sleep_c <- -1.0
B_sleep_c <-  1.0

new_profiles <- data.frame(
  sleep_c  = c(A_sleep_c,  B_sleep_c),
  sleep_c2 = c(A_sleep_c^2, B_sleep_c^2),
  study_c  = c(A_study_c,  B_study_c),
  study_c2 = c(A_study_c^2, B_study_c^2),

  attend_pct_cat = factor(c("62-72", "81-100"), levels = levels(train$attend_pct_cat)),
  trav_time = factor(c(levels(train$trav_time)[length(levels(train$trav_time))],
                       levels(train$trav_time)[1]),
                     levels = levels(train$trav_time)),
  sleep_qual = factor(c(levels(train$sleep_qual)[2], levels(train$sleep_qual)[length(levels(train$sleep_qual))]),
                     levels = levels(train$sleep_qual)),
  extra_act = factor(c("No","Yes"), levels = levels(train$extra_act)),
  parent_educ = factor(c("High school","Post graduate 2"), levels = levels(train$parent_educ)),
  school_type = factor(c("Public","Private"), levels = levels(train$school_type)),
  web_access = factor(c("No","Yes"), levels = levels(train$web_access)),
  study_method = factor(c("Notes","Mixed"), levels = levels(train$study_method))
)

rownames(new_profiles) <- c("Profile A (lower support)", "Profile B (higher support)")

pred_ci <- predict(modVIII, newdata = new_profiles, interval = "confidence", level = 0.95)
pred_out <- cbind(Profile = rownames(new_profiles), as.data.frame(pred_ci))
pred_out
```

```{r}
TermsX <- delete.response(terms(modVIII))

pred_ci <- predict(modVIII, newdata = new_profiles,
                   interval = "confidence", level = 0.95)

pred_out <- cbind(Profile = rownames(new_profiles), as.data.frame(pred_ci))
pred_out
```

```{r}
TermsX <- delete.response(terms(modVIII)) 

X <- model.matrix(TermsX, new_profiles)

beta <- coef(modVIII)
V <- vcov(modVIII)

dX <- X[2, ] - X[1, ]
diff_est <- as.numeric(dX %*% beta)
diff_se  <- sqrt(as.numeric(dX %*% V %*% dX))

tcrit <- qt(0.975, df = df.residual(modVIII))

data.frame(
  Contrast = "Profile B - Profile A",
  Predicted_difference = diff_est,
  CI_low  = diff_est - tcrit * diff_se,
  CI_high = diff_est + tcrit * diff_se
)
```
