{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP5 Naive Bayes : Spam or not-spam\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "* [0. Data preparation](#chapter0)\n",
    "* [1. Feature engineering : Text --> Vector](#chapter1)\n",
    "* [2. Naive Bayes classifier](#chapter2)\n",
    "* [3. Naive Bayes on MNIST and CIFAR10](#chapter3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data preparation <a class=\"anchor\" id=\"chapter0\"></a>\n",
    "\n",
    "We want to be able to  predict if an e-mail is a  \"spam\" or not. We will use the dataset `spam`.\n",
    "\n",
    "Reference : the dataset `spam` is taken from https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step : import the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms = pd.read_csv(\"spam.csv\", encoding='latin')\n",
    "\n",
    "sms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In column `v1`, `ham`= \"non-spam\". First we will rename the  columns `v1` and `v2` :  `v1`$\\rightarrow$ ` Label ` and `v2`$\\rightarrow$ `Texte`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms.rename(columns={'v1':'Label', 'v2':'Text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a new column, named `Labelnum` that contains zeros and ones :  `ham`$\\rightarrow$ ` 0 ` and `spam`$\\rightarrow$ ` 1 `."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms['Labelnum']=sms['Label'].map({'ham':0,'spam':1})\n",
    "\n",
    "sms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 1** : Display the sample size, the number of  hams and the number of spams. You can use the three next cells that contain hints (or not...). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint 1 for Exercise 1 \n",
    "\n",
    "a=np.array([0,1,1,1,0])\n",
    "print (len(a))\n",
    "print (a[a==0])\n",
    "print (len(a[a==0]))\n",
    "print (a[a==1])\n",
    "print (len(a[a==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint 2 for Exercise 1 \n",
    "sms[sms.Labelnum==0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint 3 for Exercise 1 \n",
    "sms[sms.Labelnum==1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer for Exercise 1\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Exercise 2** : (**Optional**) To get an overall view of the data, we can plot a histogram of the length of each SMS.\n",
    "\n",
    "Hint 1 : How to access an SMS in the data? We can use\n",
    "`pandas.DataFrame.loc`. Voir https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html\n",
    "\n",
    "Hint 2: How to create a histogram ? https://matplotlib.org/3.5.0/api/_as_gen/matplotlib.pyplot.hist.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint 1  for Exercise 2\n",
    "\n",
    "print (sms.loc[0, 'Text']) \n",
    "print (\"--> The length of the first  sms is\", len(sms.loc[0, 'Text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Answer for Exercise 2  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------\n",
    "\n",
    "## 1. Feature engineering : Text --> Vector <a class=\"anchor\" id=\"chapter1\"></a>\n",
    "\n",
    "\n",
    "In this part, we will transform the text contained in an sms into a  numerical vector in $\\mathbb{R}^{p}$. For this we will use `CountVectorizer`.\n",
    "\n",
    "Reference : https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "\n",
    "Let us first give an example of use of  `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Example = pd.DataFrame([['iphone gratuit iphone gratuit',1],['mille vert gratuit',0],\n",
    "                              ['iphone mille euro',0],['argent gratuit euro gratuit',1]],\n",
    "                             columns=['sms', 'label'])\n",
    "vec = CountVectorizer()\n",
    "X = vec.fit_transform(Example.sms)\n",
    "\n",
    "# 1. Displaying the vocabulary\n",
    "\n",
    "print (\"1. The vocabulary of Example is \", vec.vocabulary_)\n",
    "\n",
    "# 1 bis  :\n",
    "\n",
    "print('The vocabulary arranged in alphabetical order :  ', sorted(list(vec.vocabulary_.keys())))\n",
    "\n",
    "# 2. Displaying the vectors : \n",
    "\n",
    "print (\"2. The vectors corresponding to the sms are :  \\n\", X.toarray())# X.toarray because \n",
    "# X is a \"sparse\" matrix. \n",
    "\n",
    "# 3. For a new data x_0=\"iphone gratuit\", \n",
    "# you must also transform x_0 into a numerical vector before predicting. \n",
    "\n",
    "vec_x_0=vec.transform(['iphone gratuit']).toarray() # \n",
    "print (\"3. The numerical vector corresponding to  (x_0=iphone gratuit) is \\n\", vec_x_0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'sparse' version  (without \"to_array\")\n",
    "v=vec.transform(['iphone iphone gratuit'])\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"(0,2)  1\"  means :  the element in row 0 and column 2 is equal to 1.  \n",
    "# \"(0,3)  2\"  means : the element in row 0 and column 3 is equal to  2. \n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3** :\n",
    "\n",
    "1. Transform  $x_1=$ \"iphone vert gratuit\" into a numerical vector adapted to the vocabulary created with `Example`. \n",
    "\n",
    "2. Do the same with $x_2=$ \"iphone rouge gratuit\". What do you observe ?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer for Exercise 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------\n",
    "\n",
    "Let us now go back to our original dataset `sms`. Maintenant on va changer les données `sms.Texte` en vecteur et les attribuer à `X`. De plus, on va attribuer `sms.Labelnum` au `Y`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4** : Create a text-to-vector transformation model, named vectorizer. Train vectorizer on the sms.Text data.\n",
    "\n",
    "Note: We have already imported the CountVectorizer package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer for Exercise 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we split the sample into a training set and a test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.30,random_state=50)\n",
    "\n",
    "print (\"size of the training set: \", X_train.shape[0])\n",
    "\n",
    "print (\"size of the test set :\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "\n",
    "## 2. Naive Bayes classification <a class=\"anchor\" id=\"chapter2\"></a>\n",
    "\n",
    "Now we will train a Naive Bayes classification model. The class we will use is MultinomialNB from sklearn.naive_bayes.\n",
    "\n",
    "Reference : https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6** : \n",
    "\n",
    "1. Create a Naive Bayes classification model with the smoothing parameter $\\alpha$=1.0 (alpha=1.0), named `sms_bayes`.\n",
    "\n",
    "What is the role of the smoothing parameter $\\alpha$ ? Refer to the course or this page: https://scikit-learn.org/stable/modules/naive_bayes.html#multinomial-naive-bayes.\n",
    "    \n",
    "    \n",
    "\n",
    "2. Fit `sms_bayes` on (`X_train, y_train`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer for Exercise 6\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at the performance of  `sms_bayes` on the test set :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = sms_bayes.predict(X_test)\n",
    "print (\"The accuracy score on the test set is \", \n",
    "       accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "\n",
    "\n",
    "In **Exercise 1**, It was observed that in this SMS dataset, there are significantly more non-spam messages (4825) than spam messages (747). In this case, it is better to also check the confusion matrix.\n",
    "\n",
    "Reference: Confusion Matrix\n",
    " https://fr.wikipedia.org/wiki/Matrice_de_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Optional)**  \n",
    "\n",
    "Test whether your SMS will be classified as spam or not. Replace `something new` in the next cell with your SMS.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sms=vec.transform(['something new']).toarray()\n",
    "\n",
    "pred_my_sms=sms_bayes.predict(my_sms)\n",
    "\n",
    "print (pred_my_sms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Naive Bayes on MNIST and cifar-10 <a class=\"anchor\" id=\"chapter3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement Exercise 6.2 from the course handout. We will implement a Bernoulli Naive Bayes model instead of Multinomial Naive Bayes model.   For that, we will use  `BernoulliNB` in `sklearn.naive_bayes`. First let us deal with MNIST. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1, parser='auto')\n",
    "X, y = mnist.data, mnist.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7**\n",
    "1. Convert pixel values to $\\{0, 1\\}$. The pixel values range from 0 to 256. All values above 127 are converted to 1, the others to 0. \n",
    "\n",
    "2. Split into training and test sets (25% for the test set and `random_state=42`). \n",
    "\n",
    "3. Initialize and train a Bernoulli Naive Bayes classifier. \n",
    "\n",
    "4. Make the predictions on the test set and compute the accuracy score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer for Exercise 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **cifar10**, we will do the same. First let us import the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reminder : the output is an RGB image 32 x 32 \n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We need to convert the RGB values into grayscale. For that we use `cvtColor` in the `cv2` package. You may need to install the library `opencv`. \n",
    "\n",
    "Remark : `cvtColor` takes an image and the output of cifar10.load_data is an image as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert images to grayscale\n",
    "import cv2 # install opencv before, if you are not on colab\n",
    "x_train_gray = np.array([cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) for img in x_train])\n",
    "x_test_gray = np.array([cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) for img in x_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8** Implement a Bernoulli Naive Bayes classifier on the grayscale images as we did for MNIST and compute the accuracy score on the test images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer for Exercise 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(**Optional**)If you want to know more about the conversion RGB to gray scale, the formula is as follows : \n",
    "\n",
    "Y = 0.299R + 0.587G + 0.114B\n",
    "\n",
    "Where:\n",
    "\n",
    "    Y is the resulting grayscale value\n",
    "\n",
    "    R, G, and B are the red, green, and blue color channel values respectively\n",
    "\n",
    "This formula, also known as the weighted method, takes into account the human eye's different sensitivities to red, green, and blue light. Green is given the highest weight (0.587) because the human eye is most sensitive to green light, followed by red (0.299), and then blue (0.114)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
